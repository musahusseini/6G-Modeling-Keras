import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from scipy.fft import fft

# Generate synthetic RF data
np.random.seed(42)
n_samples = 1000
X = np.random.randn(n_samples, 20)  # 20 features per sample
y = np.sin(X[:, 0]) + np.cos(X[:, 1]) + np.random.normal(0, 0.5, n_samples)  # Noisy target

# Apply Fourier Transform (FFT) as feature engineering
X_fft = np.abs(fft(X, axis=1))[:, :10]  # Take first 10 frequency components

# Split into train/test sets
X_train, X_test = X_fft[:800], X_fft[800:]
y_train, y_test = y[:800], y[800:]

# Define optimized model
def build_model():
    model = keras.Sequential([
        layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
        layers.Dropout(0.1),
        layers.Dense(64, activation='relu'),
        layers.BatchNormalization(),
        layers.Dense(32, activation='relu'),
        layers.Dense(1)  # Regression output
    ])
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
                  loss=keras.losses.Huber(),
                  metrics=['mae'])
    return model

# Train the model
model = build_model()
history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)

# Make predictions
y_pred = model.predict(X_test)

# Plot predictions vs. true values
plt.figure(figsize=(10, 6))
plt.scatter(range(len(y_test)), y_test, color='blue', label='True Outputs', alpha=0.6)
plt.scatter(range(len(y_pred)), y_pred, color='orange', label='Predictions', alpha=0.6)
plt.xlabel('Sample Index')
plt.ylabel('Value')
plt.title('Model Predictions vs True Outputs')
plt.legend()
plt.grid()
plt.show()
